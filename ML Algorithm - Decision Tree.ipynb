{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "careful-concrete",
   "metadata": {},
   "source": [
    "# Decision Tree Greedy Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-vegetarian",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "meaning-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import pandas as pd\n",
    "df=pd.read_csv('titanic.csv')\n",
    "\n",
    "# Drop the unused variables\n",
    "df=df.drop(['Name'], axis=1)\n",
    "\n",
    "# df=df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "specialized-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "# Create matrices\n",
    "y, X= dmatrices('Survived ~ Age + Fare + Q(\"Siblings/Spouses Aboard\") + Q(\"Parents/Children Aboard\") + C(Pclass) + C(Sex)', df, return_type = 'dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "overhead-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove intercept\n",
    "X=X.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "public-abuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C(Pclass)[T.2]</th>\n",
       "      <th>C(Pclass)[T.3]</th>\n",
       "      <th>C(Sex)[T.male]</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Q(\"Siblings/Spouses Aboard\")</th>\n",
       "      <th>Q(\"Parents/Children Aboard\")</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C(Pclass)[T.2]  C(Pclass)[T.3]  C(Sex)[T.male]   Age     Fare  \\\n",
       "0             0.0             1.0             1.0  22.0   7.2500   \n",
       "1             0.0             0.0             0.0  38.0  71.2833   \n",
       "2             0.0             1.0             0.0  26.0   7.9250   \n",
       "3             0.0             0.0             0.0  35.0  53.1000   \n",
       "4             0.0             1.0             1.0  35.0   8.0500   \n",
       "\n",
       "   Q(\"Siblings/Spouses Aboard\")  Q(\"Parents/Children Aboard\")  \n",
       "0                           1.0                           0.0  \n",
       "1                           1.0                           0.0  \n",
       "2                           0.0                           0.0  \n",
       "3                           1.0                           0.0  \n",
       "4                           0.0                           0.0  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-pipeline",
   "metadata": {},
   "source": [
    "## Step 1: Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "solid-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Gini index is the name of the cost function used to evaluate splits in the dataset.Could entropy too but Gini is more efficient\n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "    # count all samples at split point\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # score the group based on the score for each class\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        # weight the group score by its relative size\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subsequent-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(gini_index([[[1, 1], [1, 0]], [[1, 1], [1, 0]]], [0, 1]))\n",
    "print(gini_index([[[1, 0], [1, 0]], [[1, 1], [1, 1]]], [0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-jacob",
   "metadata": {},
   "source": [
    "## Step 2: Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "local-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split based on a threshold\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "amber-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would test every single split and its gini in order to find best split\n",
    "# So this greedy algorithm need many computations\n",
    "# Use this we could find the split with minimum gini\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups=999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups=test_split(index, row[index], dataset)\n",
    "            gini=gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "                print(f'index: {b_index}, value: {b_value}, b_score: {b_score}')\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "simple-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset=np.array(pd.merge(X, y, right_index=True, left_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "employed-celtic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0, value: 0.0, b_score: 0.5\n",
      "index: 0, value: 1.0, b_score: 0.4117647058823529\n",
      "index: 1, value: 1.0, b_score: 0.36263736263736274\n",
      "index: 2, value: 1.0, b_score: 0.2525252525252525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'index': 2,\n",
       " 'value': 1.0,\n",
       " 'groups': ([array([ 0.    ,  0.    ,  0.    , 38.    , 71.2833,  1.    ,  0.    ,\n",
       "           1.    ]),\n",
       "   array([ 0.   ,  1.   ,  0.   , 26.   ,  7.925,  0.   ,  0.   ,  1.   ]),\n",
       "   array([ 0. ,  0. ,  0. , 35. , 53.1,  1. ,  0. ,  1. ]),\n",
       "   array([ 0.    ,  1.    ,  0.    , 27.    , 11.1333,  0.    ,  2.    ,\n",
       "           1.    ]),\n",
       "   array([ 1.    ,  0.    ,  0.    , 14.    , 30.0708,  1.    ,  0.    ,\n",
       "           1.    ]),\n",
       "   array([ 0. ,  1. ,  0. ,  4. , 16.7,  1. ,  1. ,  1. ]),\n",
       "   array([ 0.  ,  0.  ,  0.  , 58.  , 26.55,  0.  ,  0.  ,  1.  ]),\n",
       "   array([ 0.    ,  1.    ,  0.    , 14.    ,  7.8542,  0.    ,  0.    ,\n",
       "           0.    ]),\n",
       "   array([ 1.,  0.,  0., 55., 16.,  0.,  0.,  1.]),\n",
       "   array([ 0.,  1.,  0., 31., 18.,  1.,  0.,  0.]),\n",
       "   array([ 0.   ,  1.   ,  0.   , 22.   ,  7.225,  0.   ,  0.   ,  1.   ])],\n",
       "  [array([ 0.  ,  1.  ,  1.  , 22.  ,  7.25,  1.  ,  0.  ,  0.  ]),\n",
       "   array([ 0.  ,  1.  ,  1.  , 35.  ,  8.05,  0.  ,  0.  ,  0.  ]),\n",
       "   array([ 0.    ,  1.    ,  1.    , 27.    ,  8.4583,  0.    ,  0.    ,\n",
       "           0.    ]),\n",
       "   array([ 0.    ,  0.    ,  1.    , 54.    , 51.8625,  0.    ,  0.    ,\n",
       "           0.    ]),\n",
       "   array([ 0.   ,  1.   ,  1.   ,  2.   , 21.075,  3.   ,  1.   ,  0.   ]),\n",
       "   array([ 0.  ,  1.  ,  1.  , 20.  ,  8.05,  0.  ,  0.  ,  0.  ]),\n",
       "   array([ 0.   ,  1.   ,  1.   , 39.   , 31.275,  1.   ,  5.   ,  0.   ]),\n",
       "   array([ 0.   ,  1.   ,  1.   ,  2.   , 29.125,  4.   ,  1.   ,  0.   ]),\n",
       "   array([ 1.,  0.,  1., 23., 13.,  0.,  0.,  1.])])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "welcome-breed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1111111111111111\n",
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "# index 2 (Sex: male) is the split with smallist gini, which split the group the most\n",
    "# Let's check\n",
    "# if column=1 (male), there is only 11% survied; when the column=0 (female), there is 82% survived\n",
    "print(sum(dataset[dataset[:,2]==1][:,-1])/len(dataset[dataset[:,2]==1][:,-1]))\n",
    "print(sum(dataset[dataset[:,2]==0][:,-1])/len(dataset[dataset[:,2]==0][:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-niger",
   "metadata": {},
   "source": [
    "## Step 3: Build a Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "peripheral-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "original-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "drawn-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "harmful-empire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0, value: 0.0, b_score: 0.5\n",
      "index: 0, value: 1.0, b_score: 0.4117647058823529\n",
      "index: 1, value: 1.0, b_score: 0.36263736263736274\n",
      "index: 2, value: 1.0, b_score: 0.2525252525252525\n",
      "index: 0, value: 0.0, b_score: 0.2975206611570247\n",
      "index: 0, value: 1.0, b_score: 0.2828282828282828\n",
      "index: 1, value: 1.0, b_score: 0.2424242424242424\n",
      "index: 0, value: 0.0, b_score: 0.4444444444444444\n",
      "index: 3, value: 27.0, b_score: 0.41666666666666663\n",
      "index: 3, value: 14.0, b_score: 0.4\n",
      "index: 3, value: 31.0, b_score: 0.26666666666666655\n",
      "index: 0, value: 0.0, b_score: 0.19753086419753085\n",
      "index: 0, value: 1.0, b_score: 0.0\n",
      "index: 0, value: 0.0, b_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "tree=build_tree(dataset, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "incomplete-guest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 2,\n",
       " 'value': 1.0,\n",
       " 'left': {'index': 1,\n",
       "  'value': 1.0,\n",
       "  'left': 1.0,\n",
       "  'right': {'index': 3, 'value': 31.0, 'left': 1.0, 'right': 0.0}},\n",
       " 'right': {'index': 0,\n",
       "  'value': 1.0,\n",
       "  'left': {'index': 0, 'value': 0.0, 'left': 0.0, 'right': 0.0},\n",
       "  'right': 1.0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abroad-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "third-symposium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [X3 < 1.000]\n",
      "    [X2 < 1.000]\n",
      "     [1.0]\n",
      "     [X4 < 31.000]\n",
      "      [1.0]\n",
      "      [0.0]\n",
      "    [X1 < 1.000]\n",
      "     [X1 < 0.000]\n",
      "      [0.0]\n",
      "      [0.0]\n",
      "     [1.0]\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-therapy",
   "metadata": {},
   "source": [
    "# Decision Tree with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "partial-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import pandas as pd\n",
    "df=pd.read_csv('titanic.csv')\n",
    "\n",
    "# Drop the unused variables\n",
    "df=df.drop(['Name'], axis=1)\n",
    "\n",
    "from patsy import dmatrices\n",
    "# Create matrices\n",
    "y, X= dmatrices('Survived ~ Age + Fare + Q(\"Siblings/Spouses Aboard\") + Q(\"Parents/Children Aboard\") + C(Pclass) + C(Sex)', df, return_type = 'dataframe')\n",
    "\n",
    "#Remove intercept\n",
    "X=X.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "greatest-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,  y_train, y_test= train_test_split(X, y, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "subtle-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5, min_samples_split=5)\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "happy-funeral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(145.87714285714287, 199.32, 'X[2] <= 0.5\\ngini = 0.473\\nsamples = 798\\nvalue = [491, 307]'),\n",
       " Text(59.785714285714285, 163.07999999999998, 'X[1] <= 0.5\\ngini = 0.364\\nsamples = 276\\nvalue = [66, 210]'),\n",
       " Text(19.13142857142857, 126.83999999999999, 'X[3] <= 2.5\\ngini = 0.09\\nsamples = 148\\nvalue = [7, 141]'),\n",
       " Text(9.565714285714286, 90.6, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(28.697142857142858, 90.6, 'X[4] <= 26.125\\ngini = 0.079\\nsamples = 146\\nvalue = [6, 140]'),\n",
       " Text(19.13142857142857, 54.359999999999985, 'X[3] <= 56.0\\ngini = 0.219\\nsamples = 48\\nvalue = [6, 42]'),\n",
       " Text(9.565714285714286, 18.119999999999976, 'gini = 0.19\\nsamples = 47\\nvalue = [5, 42]'),\n",
       " Text(28.697142857142858, 18.119999999999976, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(38.26285714285714, 54.359999999999985, 'gini = 0.0\\nsamples = 98\\nvalue = [0, 98]'),\n",
       " Text(100.44, 126.83999999999999, 'X[4] <= 23.35\\ngini = 0.497\\nsamples = 128\\nvalue = [59, 69]'),\n",
       " Text(76.52571428571429, 90.6, 'X[3] <= 36.5\\ngini = 0.462\\nsamples = 105\\nvalue = [38, 67]'),\n",
       " Text(57.394285714285715, 54.359999999999985, 'X[3] <= 16.5\\ngini = 0.44\\nsamples = 98\\nvalue = [32, 66]'),\n",
       " Text(47.82857142857143, 18.119999999999976, 'gini = 0.245\\nsamples = 21\\nvalue = [3, 18]'),\n",
       " Text(66.96000000000001, 18.119999999999976, 'gini = 0.47\\nsamples = 77\\nvalue = [29, 48]'),\n",
       " Text(95.65714285714286, 54.359999999999985, 'X[3] <= 55.0\\ngini = 0.245\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(86.09142857142857, 18.119999999999976, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(105.22285714285715, 18.119999999999976, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(124.35428571428571, 90.6, 'X[6] <= 0.5\\ngini = 0.159\\nsamples = 23\\nvalue = [21, 2]'),\n",
       " Text(114.78857142857143, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(133.92000000000002, 54.359999999999985, 'X[3] <= 5.5\\ngini = 0.087\\nsamples = 22\\nvalue = [21, 1]'),\n",
       " Text(124.35428571428571, 18.119999999999976, 'gini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(143.4857142857143, 18.119999999999976, 'gini = 0.0\\nsamples = 19\\nvalue = [19, 0]'),\n",
       " Text(231.96857142857144, 163.07999999999998, 'X[3] <= 13.0\\ngini = 0.303\\nsamples = 522\\nvalue = [425, 97]'),\n",
       " Text(181.74857142857144, 126.83999999999999, 'X[5] <= 2.5\\ngini = 0.491\\nsamples = 37\\nvalue = [16, 21]'),\n",
       " Text(162.61714285714285, 90.6, 'X[6] <= 0.5\\ngini = 0.091\\nsamples = 21\\nvalue = [1, 20]'),\n",
       " Text(153.05142857142857, 54.359999999999985, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(172.18285714285713, 54.359999999999985, 'gini = 0.0\\nsamples = 19\\nvalue = [0, 19]'),\n",
       " Text(200.88, 90.6, 'X[3] <= 3.5\\ngini = 0.117\\nsamples = 16\\nvalue = [15, 1]'),\n",
       " Text(191.31428571428572, 54.359999999999985, 'X[3] <= 2.5\\ngini = 0.278\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(181.74857142857144, 18.119999999999976, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(200.88, 18.119999999999976, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(210.4457142857143, 54.359999999999985, 'gini = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(282.18857142857144, 126.83999999999999, 'X[4] <= 26.269\\ngini = 0.264\\nsamples = 485\\nvalue = [409, 76]'),\n",
       " Text(248.70857142857142, 90.6, 'X[3] <= 32.5\\ngini = 0.173\\nsamples = 355\\nvalue = [321, 34]'),\n",
       " Text(229.57714285714286, 54.359999999999985, 'X[3] <= 30.5\\ngini = 0.209\\nsamples = 244\\nvalue = [215, 29]'),\n",
       " Text(220.01142857142858, 18.119999999999976, 'gini = 0.187\\nsamples = 230\\nvalue = [206, 24]'),\n",
       " Text(239.14285714285714, 18.119999999999976, 'gini = 0.459\\nsamples = 14\\nvalue = [9, 5]'),\n",
       " Text(267.84000000000003, 54.359999999999985, 'X[4] <= 7.91\\ngini = 0.086\\nsamples = 111\\nvalue = [106, 5]'),\n",
       " Text(258.2742857142857, 18.119999999999976, 'gini = 0.0\\nsamples = 39\\nvalue = [39, 0]'),\n",
       " Text(277.4057142857143, 18.119999999999976, 'gini = 0.129\\nsamples = 72\\nvalue = [67, 5]'),\n",
       " Text(315.66857142857145, 90.6, 'X[0] <= 0.5\\ngini = 0.437\\nsamples = 130\\nvalue = [88, 42]'),\n",
       " Text(306.10285714285715, 54.359999999999985, 'X[3] <= 38.5\\ngini = 0.462\\nsamples = 116\\nvalue = [74, 42]'),\n",
       " Text(296.53714285714284, 18.119999999999976, 'gini = 0.499\\nsamples = 56\\nvalue = [29, 27]'),\n",
       " Text(315.66857142857145, 18.119999999999976, 'gini = 0.375\\nsamples = 60\\nvalue = [45, 15]'),\n",
       " Text(325.2342857142857, 54.359999999999985, 'gini = 0.0\\nsamples = 14\\nvalue = [14, 0]')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot it\n",
    "tree.plot_tree(clf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "automotive-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "heavy-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "correct=0\n",
    "for i in range(len(test_result)):\n",
    "    if test_result[i]==np.array(y_test)[i]:\n",
    "        correct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "modern-palestinian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is : 76.40449438202248%\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy is : {100*correct/len(test_result)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-graphic",
   "metadata": {},
   "source": [
    "# Let's Try the Soft Decision Tree in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "meaning-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-clone",
   "metadata": {},
   "source": [
    "## Define SDT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "prospective-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft Deicison Function built by https://github.com/xuyxu/Soft-Decision-Tree/blob/master/SDT.py\n",
    "class SDT(nn.Module):\n",
    "    \"\"\"Fast implementation of soft decision tree in PyTorch.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dim : int\n",
    "      The number of input dimensions.\n",
    "    output_dim : int\n",
    "      The number of output dimensions. For example, for a multi-class\n",
    "      classification problem with `K` classes, it is set to `K`.\n",
    "    depth : int, default=5\n",
    "      The depth of the soft decision tree. Since the soft decision tree is\n",
    "      a full binary tree, setting `depth` to a large value will drastically\n",
    "      increases the training and evaluating cost.\n",
    "    lamda : float, default=1e-3\n",
    "      The coefficient of the regularization term in the training loss. Please\n",
    "      refer to the paper on the formulation of the regularization term.\n",
    "    use_cuda : bool, default=False\n",
    "      When set to `True`, use GPU to fit the model. Training a soft decision\n",
    "      tree using CPU could be faster considering the inherent data forwarding\n",
    "      process.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    internal_node_num_ : int\n",
    "      The number of internal nodes in the tree. Given the tree depth `d`, it\n",
    "      equals to :math:`2^d - 1`.\n",
    "    leaf_node_num_ : int\n",
    "      The number of leaf nodes in the tree. Given the tree depth `d`, it equals\n",
    "      to :math:`2^d`.\n",
    "    penalty_list : list\n",
    "      A list storing the layer-wise coefficients of the regularization term.\n",
    "    inner_nodes : torch.nn.Sequential\n",
    "      A container that simulates all internal nodes in the soft decision tree.\n",
    "      The sigmoid activation function is concatenated to simulate the\n",
    "      probabilistic routing mechanism.\n",
    "    leaf_nodes : torch.nn.Linear\n",
    "      A `nn.Linear` module that simulates all leaf nodes in the tree.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            output_dim,\n",
    "            depth,\n",
    "            lamda=1e-3,\n",
    "            use_cuda=False):\n",
    "        super(SDT, self).__init__()\n",
    "        \n",
    "        self.input_dim=input_dim\n",
    "        self.output_dim=output_dim\n",
    "        \n",
    "        self.depth=depth\n",
    "        self.lamda=lamda\n",
    "        self.device=torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        \n",
    "        self._validate_parameters()\n",
    "        \n",
    "        self.internal_node_num_=2**self.depth-1\n",
    "        self.leaf_node_num_=2**self.depth\n",
    "        \n",
    "        \"\"\"\n",
    "        As per paper, We found that we achieved better test accuracy results\n",
    "        when the strength of the penalty decayed exponentially with the depth d of the\n",
    "        node in the tree so that it was proportional to 2−d\n",
    ".\n",
    "        \"\"\"\n",
    "        \n",
    "        # Different penalty coefficients for nodes in different layers\n",
    "        self.penalty_list = [\n",
    "            self.lamda * (2 ** (-depth)) for depth in range(0, self.depth)\n",
    "        ]\n",
    "        \n",
    "        # Initialize internal nodes and leaf nodes, the input dimension on\n",
    "        # internal nodes is added by 1, serving as the bias.\n",
    "        \n",
    "        \"\"\"\n",
    "        As per paper, We use soft binary decision trees trained with mini-batch gradient descent, where\n",
    "        each inner node i has a learned filter wi and a bias bi\n",
    "        , and each leaf node `\n",
    "        has a learned distribution Q`. At each inner node, the probability of taking the\n",
    "        rightmost branch is:\n",
    "        pi(x) = σ(xwi + bi)\n",
    "        \n",
    "        where x is the input to the model and σ is the sigmoid logistic function\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.inner_nodes = nn.Sequential(\n",
    "            nn.Linear(self.input_dim + 1, self.internal_node_num_, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.leaf_nodes = nn.Linear(self.leaf_node_num_,\n",
    "                                    self.output_dim,\n",
    "                                    bias=False)\n",
    "        \n",
    "    def forward(self, X, is_training_data=False):\n",
    "        _mu, _penalty = self._forward(X)\n",
    "        y_pred = self.leaf_nodes(_mu)\n",
    "\n",
    "        # When `X` is the training data, the model also returns the penalty\n",
    "        # to compute the training loss.\n",
    "        if is_training_data:\n",
    "            return y_pred, _penalty\n",
    "        else:\n",
    "            return y_pred\n",
    "        \n",
    "    def _forward(self, X):\n",
    "        \"\"\"Implementation on the data forwarding process.\"\"\"\n",
    "\n",
    "        # batch_size is the # of rows\n",
    "        batch_size = X.size()[0]\n",
    "        X = self._data_augment(X)\n",
    "        \n",
    "        path_prob = self.inner_nodes(X)\n",
    "        path_prob = torch.unsqueeze(path_prob, dim=2)\n",
    "        \n",
    "        path_prob = torch.cat((path_prob, 1 - path_prob), dim=2)\n",
    "        \n",
    "        _mu = X.data.new(batch_size, 1, 1).fill_(1.0)\n",
    "        _penalty = torch.tensor(0.0).to(self.device)\n",
    "        \n",
    "        # Iterate through internal odes in each layer to compute the final path\n",
    "        # probabilities and the regularization term.\n",
    "        begin_idx = 0\n",
    "        end_idx = 1\n",
    "        \n",
    "        for layer_idx in range(0, self.depth):\n",
    "            _path_prob = path_prob[:, begin_idx:end_idx, :]\n",
    "            \n",
    "            # Extract internal nodes in the current layer to compute the\n",
    "            # regularization term\n",
    "            _penalty = _penalty + self._cal_penalty(layer_idx, _mu, _path_prob)\n",
    "            _mu = _mu.view(batch_size, -1, 1).repeat(1, 1, 2)\n",
    "            \n",
    "            \"\"\"\n",
    "            As per paper, This model can be used to give a predictive distribution over classes in two\n",
    "            different ways, namely by using the distribution from the leaf with the greatest\n",
    "            path probability or averaging the distributions over all the leaves, weighted by\n",
    "            their respective path probabilities. If we take the predictive distribution from\n",
    "            the leaf with the greatest path probability, the explanation for that prediction is\n",
    "            simply the list of all the filters along the path from the route to the leaf together\n",
    "            with the binary activation decisions\n",
    "            \"\"\"\n",
    "            _mu = _mu * _path_prob  # update path probabilities\n",
    "            \n",
    "            begin_idx = end_idx\n",
    "            end_idx = begin_idx + 2 ** (layer_idx + 1)\n",
    "        \n",
    "        mu = _mu.view(batch_size, self.leaf_node_num_)\n",
    "        \n",
    "        return mu, _penalty\n",
    "    \n",
    "    def _cal_penalty(self, layer_idx, _mu, _path_prob):\n",
    "        \"\"\"\n",
    "        Compute the regularization term for internal nodes in different layers.\n",
    "        \"\"\"\n",
    "\n",
    "        penalty = torch.tensor(0.0).to(self.device)\n",
    "\n",
    "        batch_size = _mu.size()[0]\n",
    "        _mu = _mu.view(batch_size, 2 ** layer_idx)\n",
    "        _path_prob = _path_prob.view(batch_size, 2 ** (layer_idx + 1))\n",
    "        \n",
    "        # Get the regularization term\n",
    "        for node in range(0, 2 ** (layer_idx + 1)):\n",
    "            alpha = torch.sum(\n",
    "                _path_prob[:, node] * _mu[:, node // 2], dim=0\n",
    "            ) / torch.sum(_mu[:, node // 2], dim=0)\n",
    "\n",
    "            coeff = self.penalty_list[layer_idx]\n",
    "\n",
    "            penalty -= 0.5 * coeff * (torch.log(alpha) + torch.log(1 - alpha))\n",
    "\n",
    "        return penalty\n",
    "    \n",
    "    def _data_augment(self, X):\n",
    "        \"\"\"Add a constant input `1` onto the front of each sample.\"\"\"\n",
    "        batch_size = X.size()[0]\n",
    "        X = X.view(batch_size, -1)\n",
    "        bias = torch.ones(batch_size, 1).to(self.device)\n",
    "        X = torch.cat((bias, X), 1)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def _validate_parameters(self):\n",
    "\n",
    "        if not self.depth > 0:\n",
    "            msg = (\"The tree depth should be strictly positive, but got {}\"\n",
    "                   \"instead.\")\n",
    "            raise ValueError(msg.format(self.depth))\n",
    "\n",
    "        if not self.lamda >= 0:\n",
    "            msg = (\n",
    "                \"The coefficient of the regularization term should not be\"\n",
    "                \" negative, but got {} instead.\"\n",
    "            )\n",
    "            raise ValueError(msg.format(self.lamda)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-native",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "usual-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import pandas as pd\n",
    "df=pd.read_csv('titanic.csv')\n",
    "\n",
    "# Drop the unused variables\n",
    "df=df.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "together-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "# Create matrices\n",
    "y, X= dmatrices('Survived ~ Age + Fare + Q(\"Siblings/Spouses Aboard\") + Q(\"Parents/Children Aboard\") + C(Pclass) + C(Sex)', df, return_type = 'dataframe')\n",
    "\n",
    "#Remove intercept\n",
    "X=X.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "sized-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_continous=X[['Age', 'Fare', 'Q(\"Siblings/Spouses Aboard\")', 'Q(\"Parents/Children Aboard\")']]\n",
    "X_class=X[['C(Pclass)[T.2]', 'C(Pclass)[T.3]', 'C(Sex)[T.male]']]\n",
    "\n",
    "# Let standardize the data\n",
    "from sklearn import preprocessing\n",
    "standard_scaler=preprocessing.StandardScaler()\n",
    "scaled_X = standard_scaler.fit_transform(X_continous)\n",
    "\n",
    "df_array=np.hstack((np.array(X_class), scaled_X, np.array(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "extraordinary-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test= train_test_split(df_array, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "corresponding-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_train=torch.from_numpy(np.array(df_train)).float()\n",
    "tensor_test=torch.from_numpy(np.array(df_test)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "varied-syntax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([798, 8])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_train.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-computer",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "considerable-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "subject-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_coding(target, device, output_dim):\n",
    "    \"\"\"Convert the class labels into one-hot encoded vectors.\"\"\"\n",
    "    target_onehot = torch.FloatTensor(target.size()[0], output_dim).to(device)\n",
    "    target_onehot.data.zero_()\n",
    "    target_onehot.scatter_(1, target.view(-1, 1), 1.0)\n",
    "    return target_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "irish-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_dim = 7          # the number of input dimensions\n",
    "output_dim = 2         # the number of outputs (i.e., # classes on MNIST)\n",
    "depth = 5              # tree depth\n",
    "lamda = 1e-3           # coefficient of the regularization term\n",
    "lr = 1e-3              # learning rate\n",
    "weight_decaly = 5e-4   # weight decay\n",
    "batch_size = 797       # batch size\n",
    "epochs = 20            # the number of training epochs\n",
    "log_interval = 100      # the number of batches to wait before printing logs\n",
    "use_cuda = False       # whether to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "atomic-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and Optimizer\n",
    "tree = SDT(input_dim, output_dim, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "vocational-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(tree.parameters(), lr=lr, weight_decay=weight_decaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "prepared-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_testing_acc = 0.0\n",
    "testing_acc_list = []\n",
    "training_loss_list = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "solid-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 | Batch: 000 | Loss: 0.70943 | Correct: 000/001\n",
      "Epoch: 00 | Batch: 100 | Loss: 0.68963 | Correct: 001/001\n",
      "Epoch: 00 | Batch: 200 | Loss: 0.65516 | Correct: 001/001\n",
      "Epoch: 00 | Batch: 300 | Loss: 0.79931 | Correct: 000/001\n",
      "Epoch: 00 | Batch: 400 | Loss: 0.80548 | Correct: 000/001\n",
      "Epoch: 00 | Batch: 500 | Loss: 0.82915 | Correct: 000/001\n",
      "Epoch: 00 | Batch: 600 | Loss: 0.83691 | Correct: 000/001\n",
      "Epoch: 00 | Batch: 700 | Loss: 0.55794 | Correct: 001/001\n",
      "\n",
      "Epoch: 00 | Testing Accuracy: 60.0/89 (67.416%) | Historical Best: 67.416%\n",
      "\n",
      "Epoch: 01 | Batch: 000 | Loss: 0.89937 | Correct: 000/001\n",
      "Epoch: 01 | Batch: 100 | Loss: 0.53603 | Correct: 001/001\n",
      "Epoch: 01 | Batch: 200 | Loss: 0.53630 | Correct: 001/001\n",
      "Epoch: 01 | Batch: 300 | Loss: 1.14811 | Correct: 000/001\n",
      "Epoch: 01 | Batch: 400 | Loss: 0.97512 | Correct: 000/001\n",
      "Epoch: 01 | Batch: 500 | Loss: 1.00899 | Correct: 000/001\n",
      "Epoch: 01 | Batch: 600 | Loss: 0.97210 | Correct: 000/001\n",
      "Epoch: 01 | Batch: 700 | Loss: 0.48596 | Correct: 001/001\n",
      "\n",
      "Epoch: 01 | Testing Accuracy: 68.0/89 (76.404%) | Historical Best: 76.404%\n",
      "\n",
      "Epoch: 02 | Batch: 000 | Loss: 1.01732 | Correct: 000/001\n",
      "Epoch: 02 | Batch: 100 | Loss: 0.43493 | Correct: 001/001\n",
      "Epoch: 02 | Batch: 200 | Loss: 0.49512 | Correct: 001/001\n",
      "Epoch: 02 | Batch: 300 | Loss: 1.38749 | Correct: 000/001\n",
      "Epoch: 02 | Batch: 400 | Loss: 0.98377 | Correct: 000/001\n",
      "Epoch: 02 | Batch: 500 | Loss: 1.02508 | Correct: 000/001\n",
      "Epoch: 02 | Batch: 600 | Loss: 1.02671 | Correct: 000/001\n",
      "Epoch: 02 | Batch: 700 | Loss: 0.51391 | Correct: 001/001\n",
      "\n",
      "Epoch: 02 | Testing Accuracy: 71.0/89 (79.775%) | Historical Best: 79.775%\n",
      "\n",
      "Epoch: 03 | Batch: 000 | Loss: 0.99090 | Correct: 000/001\n",
      "Epoch: 03 | Batch: 100 | Loss: 0.37423 | Correct: 001/001\n",
      "Epoch: 03 | Batch: 200 | Loss: 0.48696 | Correct: 001/001\n",
      "Epoch: 03 | Batch: 300 | Loss: 1.51848 | Correct: 000/001\n",
      "Epoch: 03 | Batch: 400 | Loss: 0.90586 | Correct: 000/001\n",
      "Epoch: 03 | Batch: 500 | Loss: 0.96193 | Correct: 000/001\n",
      "Epoch: 03 | Batch: 600 | Loss: 1.06134 | Correct: 000/001\n",
      "Epoch: 03 | Batch: 700 | Loss: 0.58332 | Correct: 001/001\n",
      "\n",
      "Epoch: 03 | Testing Accuracy: 73.0/89 (82.022%) | Historical Best: 82.022%\n",
      "\n",
      "Epoch: 04 | Batch: 000 | Loss: 0.91532 | Correct: 000/001\n",
      "Epoch: 04 | Batch: 100 | Loss: 0.32745 | Correct: 001/001\n",
      "Epoch: 04 | Batch: 200 | Loss: 0.47534 | Correct: 001/001\n",
      "Epoch: 04 | Batch: 300 | Loss: 1.61278 | Correct: 000/001\n",
      "Epoch: 04 | Batch: 400 | Loss: 0.81109 | Correct: 000/001\n",
      "Epoch: 04 | Batch: 500 | Loss: 0.88134 | Correct: 000/001\n",
      "Epoch: 04 | Batch: 600 | Loss: 1.09186 | Correct: 000/001\n",
      "Epoch: 04 | Batch: 700 | Loss: 0.66788 | Correct: 001/001\n",
      "\n",
      "Epoch: 04 | Testing Accuracy: 75.0/89 (84.270%) | Historical Best: 84.270%\n",
      "\n",
      "Epoch: 05 | Batch: 000 | Loss: 0.83420 | Correct: 000/001\n",
      "Epoch: 05 | Batch: 100 | Loss: 0.29048 | Correct: 001/001\n",
      "Epoch: 05 | Batch: 200 | Loss: 0.45620 | Correct: 001/001\n",
      "Epoch: 05 | Batch: 300 | Loss: 1.68980 | Correct: 000/001\n",
      "Epoch: 05 | Batch: 400 | Loss: 0.72532 | Correct: 000/001\n",
      "Epoch: 05 | Batch: 500 | Loss: 0.80623 | Correct: 000/001\n",
      "Epoch: 05 | Batch: 600 | Loss: 1.11656 | Correct: 000/001\n",
      "Epoch: 05 | Batch: 700 | Loss: 0.75337 | Correct: 000/001\n",
      "\n",
      "Epoch: 05 | Testing Accuracy: 77.0/89 (86.517%) | Historical Best: 86.517%\n",
      "\n",
      "Epoch: 06 | Batch: 000 | Loss: 0.76279 | Correct: 000/001\n",
      "Epoch: 06 | Batch: 100 | Loss: 0.26199 | Correct: 001/001\n",
      "Epoch: 06 | Batch: 200 | Loss: 0.43376 | Correct: 001/001\n",
      "Epoch: 06 | Batch: 300 | Loss: 1.75486 | Correct: 000/001\n",
      "Epoch: 06 | Batch: 400 | Loss: 0.65551 | Correct: 001/001\n",
      "Epoch: 06 | Batch: 500 | Loss: 0.74353 | Correct: 000/001\n",
      "Epoch: 06 | Batch: 600 | Loss: 1.13232 | Correct: 000/001\n",
      "Epoch: 06 | Batch: 700 | Loss: 0.83198 | Correct: 000/001\n",
      "\n",
      "Epoch: 06 | Testing Accuracy: 78.0/89 (87.640%) | Historical Best: 87.640%\n",
      "\n",
      "Epoch: 07 | Batch: 000 | Loss: 0.70468 | Correct: 000/001\n",
      "Epoch: 07 | Batch: 100 | Loss: 0.24030 | Correct: 001/001\n",
      "Epoch: 07 | Batch: 200 | Loss: 0.41147 | Correct: 001/001\n",
      "Epoch: 07 | Batch: 300 | Loss: 1.81032 | Correct: 000/001\n",
      "Epoch: 07 | Batch: 400 | Loss: 0.60134 | Correct: 001/001\n",
      "Epoch: 07 | Batch: 500 | Loss: 0.69388 | Correct: 001/001\n",
      "Epoch: 07 | Batch: 600 | Loss: 1.13755 | Correct: 000/001\n",
      "Epoch: 07 | Batch: 700 | Loss: 0.90011 | Correct: 000/001\n",
      "\n",
      "Epoch: 07 | Testing Accuracy: 79.0/89 (88.764%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 08 | Batch: 000 | Loss: 0.65923 | Correct: 001/001\n",
      "Epoch: 08 | Batch: 100 | Loss: 0.22381 | Correct: 001/001\n",
      "Epoch: 08 | Batch: 200 | Loss: 0.39089 | Correct: 001/001\n",
      "Epoch: 08 | Batch: 300 | Loss: 1.85776 | Correct: 000/001\n",
      "Epoch: 08 | Batch: 400 | Loss: 0.56017 | Correct: 001/001\n",
      "Epoch: 08 | Batch: 500 | Loss: 0.65559 | Correct: 001/001\n",
      "Epoch: 08 | Batch: 600 | Loss: 1.13209 | Correct: 000/001\n",
      "Epoch: 08 | Batch: 700 | Loss: 0.95707 | Correct: 000/001\n",
      "\n",
      "Epoch: 08 | Testing Accuracy: 79.0/89 (88.764%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 09 | Batch: 000 | Loss: 0.62431 | Correct: 001/001\n",
      "Epoch: 09 | Batch: 100 | Loss: 0.21119 | Correct: 001/001\n",
      "Epoch: 09 | Batch: 200 | Loss: 0.37247 | Correct: 001/001\n",
      "Epoch: 09 | Batch: 300 | Loss: 1.89846 | Correct: 000/001\n",
      "Epoch: 09 | Batch: 400 | Loss: 0.52904 | Correct: 001/001\n",
      "Epoch: 09 | Batch: 500 | Loss: 0.62639 | Correct: 001/001\n",
      "Epoch: 09 | Batch: 600 | Loss: 1.11707 | Correct: 000/001\n",
      "Epoch: 09 | Batch: 700 | Loss: 1.00375 | Correct: 000/001\n",
      "\n",
      "Epoch: 09 | Testing Accuracy: 78.0/89 (87.640%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 10 | Batch: 000 | Loss: 0.59767 | Correct: 001/001\n",
      "Epoch: 10 | Batch: 100 | Loss: 0.20142 | Correct: 001/001\n",
      "Epoch: 10 | Batch: 200 | Loss: 0.35614 | Correct: 001/001\n",
      "Epoch: 10 | Batch: 300 | Loss: 1.93349 | Correct: 000/001\n",
      "Epoch: 10 | Batch: 400 | Loss: 0.50541 | Correct: 001/001\n",
      "Epoch: 10 | Batch: 500 | Loss: 0.60423 | Correct: 001/001\n",
      "Epoch: 10 | Batch: 600 | Loss: 1.09437 | Correct: 000/001\n",
      "Epoch: 10 | Batch: 700 | Loss: 1.04164 | Correct: 000/001\n",
      "\n",
      "Epoch: 10 | Testing Accuracy: 78.0/89 (87.640%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 11 | Batch: 000 | Loss: 0.57742 | Correct: 001/001\n",
      "Epoch: 11 | Batch: 100 | Loss: 0.19376 | Correct: 001/001\n",
      "Epoch: 11 | Batch: 200 | Loss: 0.34170 | Correct: 001/001\n",
      "Epoch: 11 | Batch: 300 | Loss: 1.96360 | Correct: 000/001\n",
      "Epoch: 11 | Batch: 400 | Loss: 0.48734 | Correct: 001/001\n",
      "Epoch: 11 | Batch: 500 | Loss: 0.58742 | Correct: 001/001\n",
      "Epoch: 11 | Batch: 600 | Loss: 1.06612 | Correct: 000/001\n",
      "Epoch: 11 | Batch: 700 | Loss: 1.07230 | Correct: 000/001\n",
      "\n",
      "Epoch: 11 | Testing Accuracy: 79.0/89 (88.764%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 12 | Batch: 000 | Loss: 0.56205 | Correct: 001/001\n",
      "Epoch: 12 | Batch: 100 | Loss: 0.18768 | Correct: 001/001\n",
      "Epoch: 12 | Batch: 200 | Loss: 0.32892 | Correct: 001/001\n",
      "Epoch: 12 | Batch: 300 | Loss: 1.98935 | Correct: 000/001\n",
      "Epoch: 12 | Batch: 400 | Loss: 0.47337 | Correct: 001/001\n",
      "Epoch: 12 | Batch: 500 | Loss: 0.57465 | Correct: 001/001\n",
      "Epoch: 12 | Batch: 600 | Loss: 1.03442 | Correct: 000/001\n",
      "Epoch: 12 | Batch: 700 | Loss: 1.09714 | Correct: 000/001\n",
      "\n",
      "Epoch: 12 | Testing Accuracy: 79.0/89 (88.764%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 13 | Batch: 000 | Loss: 0.55040 | Correct: 001/001\n",
      "Epoch: 13 | Batch: 100 | Loss: 0.18283 | Correct: 001/001\n",
      "Epoch: 13 | Batch: 200 | Loss: 0.31764 | Correct: 001/001\n",
      "Epoch: 13 | Batch: 300 | Loss: 2.01111 | Correct: 000/001\n",
      "Epoch: 13 | Batch: 400 | Loss: 0.46245 | Correct: 001/001\n",
      "Epoch: 13 | Batch: 500 | Loss: 0.56491 | Correct: 001/001\n",
      "Epoch: 13 | Batch: 600 | Loss: 1.00109 | Correct: 000/001\n",
      "Epoch: 13 | Batch: 700 | Loss: 1.11733 | Correct: 000/001\n",
      "\n",
      "Epoch: 13 | Testing Accuracy: 78.0/89 (87.640%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 14 | Batch: 000 | Loss: 0.54156 | Correct: 001/001\n",
      "Epoch: 14 | Batch: 100 | Loss: 0.17893 | Correct: 001/001\n",
      "Epoch: 14 | Batch: 200 | Loss: 0.30768 | Correct: 001/001\n",
      "Epoch: 14 | Batch: 300 | Loss: 2.02923 | Correct: 000/001\n",
      "Epoch: 14 | Batch: 400 | Loss: 0.45384 | Correct: 001/001\n",
      "Epoch: 14 | Batch: 500 | Loss: 0.55745 | Correct: 001/001\n",
      "Epoch: 14 | Batch: 600 | Loss: 0.96757 | Correct: 000/001\n",
      "Epoch: 14 | Batch: 700 | Loss: 1.13376 | Correct: 000/001\n",
      "\n",
      "Epoch: 14 | Testing Accuracy: 78.0/89 (87.640%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 15 | Batch: 000 | Loss: 0.53487 | Correct: 001/001\n",
      "Epoch: 15 | Batch: 100 | Loss: 0.17577 | Correct: 001/001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Batch: 200 | Loss: 0.29891 | Correct: 001/001\n",
      "Epoch: 15 | Batch: 300 | Loss: 2.04405 | Correct: 000/001\n",
      "Epoch: 15 | Batch: 400 | Loss: 0.44699 | Correct: 001/001\n",
      "Epoch: 15 | Batch: 500 | Loss: 0.55171 | Correct: 001/001\n",
      "Epoch: 15 | Batch: 600 | Loss: 0.93488 | Correct: 000/001\n",
      "Epoch: 15 | Batch: 700 | Loss: 1.14714 | Correct: 000/001\n",
      "\n",
      "Epoch: 15 | Testing Accuracy: 78.0/89 (87.640%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 16 | Batch: 000 | Loss: 0.52980 | Correct: 001/001\n",
      "Epoch: 16 | Batch: 100 | Loss: 0.17322 | Correct: 001/001\n",
      "Epoch: 16 | Batch: 200 | Loss: 0.29119 | Correct: 001/001\n",
      "Epoch: 16 | Batch: 300 | Loss: 2.05592 | Correct: 000/001\n",
      "Epoch: 16 | Batch: 400 | Loss: 0.44152 | Correct: 001/001\n",
      "Epoch: 16 | Batch: 500 | Loss: 0.54728 | Correct: 001/001\n",
      "Epoch: 16 | Batch: 600 | Loss: 0.90369 | Correct: 000/001\n",
      "Epoch: 16 | Batch: 700 | Loss: 1.15797 | Correct: 000/001\n",
      "\n",
      "Epoch: 16 | Testing Accuracy: 78.0/89 (87.640%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 17 | Batch: 000 | Loss: 0.52598 | Correct: 001/001\n",
      "Epoch: 17 | Batch: 100 | Loss: 0.17115 | Correct: 001/001\n",
      "Epoch: 17 | Batch: 200 | Loss: 0.28437 | Correct: 001/001\n",
      "Epoch: 17 | Batch: 300 | Loss: 2.06520 | Correct: 000/001\n",
      "Epoch: 17 | Batch: 400 | Loss: 0.43718 | Correct: 001/001\n",
      "Epoch: 17 | Batch: 500 | Loss: 0.54386 | Correct: 001/001\n",
      "Epoch: 17 | Batch: 600 | Loss: 0.87434 | Correct: 000/001\n",
      "Epoch: 17 | Batch: 700 | Loss: 1.16666 | Correct: 000/001\n",
      "\n",
      "Epoch: 17 | Testing Accuracy: 78.0/89 (87.640%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 18 | Batch: 000 | Loss: 0.52313 | Correct: 001/001\n",
      "Epoch: 18 | Batch: 100 | Loss: 0.16945 | Correct: 001/001\n",
      "Epoch: 18 | Batch: 200 | Loss: 0.27832 | Correct: 001/001\n",
      "Epoch: 18 | Batch: 300 | Loss: 2.07228 | Correct: 000/001\n",
      "Epoch: 18 | Batch: 400 | Loss: 0.43374 | Correct: 001/001\n",
      "Epoch: 18 | Batch: 500 | Loss: 0.54124 | Correct: 001/001\n",
      "Epoch: 18 | Batch: 600 | Loss: 0.84696 | Correct: 000/001\n",
      "Epoch: 18 | Batch: 700 | Loss: 1.17351 | Correct: 000/001\n",
      "\n",
      "Epoch: 18 | Testing Accuracy: 78.0/89 (87.640%) | Historical Best: 88.764%\n",
      "\n",
      "Epoch: 19 | Batch: 000 | Loss: 0.52104 | Correct: 001/001\n",
      "Epoch: 19 | Batch: 100 | Loss: 0.16805 | Correct: 001/001\n",
      "Epoch: 19 | Batch: 200 | Loss: 0.27294 | Correct: 001/001\n",
      "Epoch: 19 | Batch: 300 | Loss: 2.07749 | Correct: 000/001\n",
      "Epoch: 19 | Batch: 400 | Loss: 0.43108 | Correct: 001/001\n",
      "Epoch: 19 | Batch: 500 | Loss: 0.53926 | Correct: 001/001\n",
      "Epoch: 19 | Batch: 600 | Loss: 0.82153 | Correct: 000/001\n",
      "Epoch: 19 | Batch: 700 | Loss: 1.17876 | Correct: 000/001\n",
      "\n",
      "Epoch: 19 | Testing Accuracy: 78.0/89 (87.640%) | Historical Best: 88.764%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):    \n",
    "    tree.train()\n",
    "    \n",
    "    for batch_idx, dataset in enumerate(tensor_train):\n",
    "        \n",
    "        data=dataset[:-1].view(1,-1)\n",
    "        target=dataset[-1:].to(torch.long)\n",
    "        batch_size=data.size()[0]\n",
    "        \n",
    "        target_onehot=onehot_coding(target, device, output_dim)\n",
    "        \n",
    "        output, penalty=tree.forward(data, is_training_data=True)\n",
    "        \n",
    "        loss = criterion(output, target.view(-1))\n",
    "        \n",
    "        loss+=penalty\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct = pred.eq(target.view(-1).data).sum()\n",
    "\n",
    "            msg = (\n",
    "                \"Epoch: {:02d} | Batch: {:03d} | Loss: {:.5f} |\"\n",
    "                \" Correct: {:03d}/{:03d}\"\n",
    "            )\n",
    "            print(msg.format(epoch, batch_idx, loss, correct, batch_size))\n",
    "            training_loss_list.append(loss.cpu().data.numpy())\n",
    "        \n",
    "    # Evaluating\n",
    "    tree.eval()\n",
    "    correct = 0.\n",
    "\n",
    "    for batch_idx, dataset in enumerate(tensor_test):\n",
    "\n",
    "        data=dataset[:-1].view(1,-1)\n",
    "        target=dataset[-1:].to(torch.long)\n",
    "        batch_size=data.size()[0]\n",
    "\n",
    "        output = F.softmax(tree.forward(data), dim=1)\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += pred.eq(target.view(-1).data).sum()\n",
    "\n",
    "    accuracy = 100.0 * float(correct) / len(tensor_test)\n",
    "\n",
    "    if accuracy > best_testing_acc:\n",
    "        best_testing_acc = accuracy\n",
    "\n",
    "    msg = (\n",
    "        \"\\nEpoch: {:02d} | Testing Accuracy: {}/{} ({:.3f}%) |\"\n",
    "        \" Historical Best: {:.3f}%\\n\"\n",
    "    )\n",
    "    print(\n",
    "        msg.format(\n",
    "            epoch, correct,\n",
    "            len(tensor_test),\n",
    "            accuracy,\n",
    "            best_testing_acc\n",
    "        )\n",
    "    )\n",
    "    testing_acc_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-polyester",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
